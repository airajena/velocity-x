input {
  # TCP input from application (Logstash Logback Encoder)
  tcp {
    port => 5000
    codec => json_lines
    type => "application-logs"
  }
  
  # File input as backup
  file {
    path => "/usr/share/logstash/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
    type => "file-logs"
  }
}

filter {
  # Parse JSON logs
  if [type] == "application-logs" {
    json {
      source => "message"
    }
  }
  
  # Add timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # Extract log level
  if [level] {
    mutate {
      add_field => { "log_level" => "%{level}" }
    }
  }
  
  # Extract trace information
  if [traceId] {
    mutate {
      add_field => { "trace_id" => "%{traceId}" }
    }
  }
  
  if [spanId] {
    mutate {
      add_field => { "span_id" => "%{spanId}" }
    }
  }
  
  # Extract user information
  if [userId] {
    mutate {
      add_field => { "user_id" => "%{userId}" }
    }
  }
  
  # Add environment tags
  mutate {
    add_field => {
      "service" => "user-service"
      "environment" => "${ENVIRONMENT:development}"
    }
  }
  
  # Grok patterns for unstructured logs
  grok {
    match => {
      "message" => [
        "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:log_message}",
        "%{TIMESTAMP_ISO8601:timestamp} - %{GREEDYDATA:log_message}"
      ]
    }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "port" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "user-service-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # Output to console for debugging (disable in production)
  stdout {
    codec => rubydebug
  }
}
